#!/usr/bin/env python
# coding: utf-8

# training of the gbm model with all GVAE-reduced features (with RFE selection)# In[3]:


import pickle

import torch
import numpy as np
from torch_geometric.data import Data, DataLoader
from torch_geometric.utils import train_test_split_edges
from sklearn.ensemble import GradientBoostingClassifier

[gae, Labels]=pickle.load(open("data_gae_40.p","rb"))

arr=[]


for i in range(0,len(gae)):      
    arr.append(np.mean(np.array(gae[i]),axis=0))
    print (len(arr))

train_all=np.array(arr)
y= np.array(Labels)



[gae_v, Labels_v]=pickle.load(open("data_gae_50.p","rb"))
arr_v=[]

for i in range(0,len(gae_v)):    
    arr_v.append(np.mean(np.array(gae_v[i]),axis=0))
    print (len(arr_v))

train_v=np.array(arr_v)
y_v= np.array(Labels_v)





[gae_z, Labels_z]=pickle.load(open("data_gae_30.p","rb"))
arr_z=[]

for i in range(0,len(gae_z)):    
  
    arr_z.append(np.mean(np.array(gae_z[i]),axis=0))
    print (len(arr_z))

train_z=np.array(arr_z)
y_z= np.array(Labels_z)




[gae_x, Labels_x]=pickle.load(open("data_gae_20.p","rb"))
arr_x=[]

for i in range(0,len(gae_z)):    
  
    arr_x.append(np.mean(np.array(gae_x[i]),axis=0))
    print (len(arr_x))

train_x=np.array(arr_x)
y_x= np.array(Labels_x)




from sklearn.model_selection import KFold
from sklearn.metrics import f1_score
from sklearn.feature_selection import RFE
from sklearn.svm import SVR
import pandas as pd
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

k_folds = 10
max_depth=[9,11]
min_split=[2,3,4]


ns=[30,40,50]
all_results=pd.DataFrame(columns=["n","c","kernel","acc","fm","acc_folds","fm_folds"])
cnt=0
kfold = KFold(n_splits=k_folds, shuffle=True,random_state=123)
train_c=np.concatenate((train_all,train_v),axis=1)
train_c=np.concatenate((train_c,train_z),axis=1)
train_c=np.concatenate((train_c,train_x),axis=1)

for n in ns:
    rf = RandomForestClassifier(n_estimators=200)
    rfe = RFE(estimator=rf, n_features_to_select=n, step=1,verbose=1)
    rfe.fit(train_c, y)
    train=rfe.transform(train_c)
    
    for dept in max_depth:
        for split in min_split:
            acc_results=[]
            f_results=[]
            print (k)
            for fold, (train_ids, test_ids) in enumerate(kfold.split(train)):
                print(f'FOLD {fold}')
                print('--------------------------------')

                clf = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.01,
                max_depth=dept, random_state=0,verbose=1,min_samples_split=split).fit(train[train_ids], y[train_ids])

                acc_results.append(clf.score(train[test_ids,:], y[test_ids]))
                f_results.append(f1_score(y[test_ids],clf.predict(train[test_ids])))

            all_results.loc[cnt]=[n,c,k,np.mean(acc_results),np.mean(f_results),acc_results,f_results]
            print (all_results)
            cnt=cnt+1



all_results.to_csv("rfe_svm_gae.csv",index=False)





